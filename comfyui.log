## ComfyUI-Manager: installing dependencies done.
[2024-06-03 23:04] ** ComfyUI startup time: 2024-06-03 23:04:22.483160
[2024-06-03 23:04] ** Platform: Linux
[2024-06-03 23:04] ** Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
[2024-06-03 23:04] ** Python executable: /home/cash/ComfyUI/venv/bin/python
[2024-06-03 23:04] ** Log path: /home/cash/ComfyUI/comfyui.log
[2024-06-03 23:04] 
Prestartup times for custom nodes:
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/rgthree-comfy
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-Manager
[2024-06-03 23:04] 
Total VRAM 20154 MB, total RAM 64103 MB
[2024-06-03 23:04] pytorch version: 2.3.0+cu121
[2024-06-03 23:04] Set vram state to: HIGH_VRAM
[2024-06-03 23:04] Device: cuda:0 NVIDIA RTX 4000 SFF Ada Generation : cudaMallocAsync
[2024-06-03 23:04] VAE dtype: torch.bfloat16
[2024-06-03 23:04] Using pytorch cross attention
[2024-06-03 23:04] [36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /home/cash/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts[0m
[2024-06-03 23:04] [36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False[0m
[2024-06-03 23:04] [36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider'][0m
[2024-06-03 23:04] /home/cash/ComfyUI/custom_nodes/comfyui_controlnet_aux/node_wrappers/dwpose.py:26: UserWarning: DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly
  warnings.warn("DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly")
[2024-06-03 23:04] [34mWAS Node Suite: [0mOpenCV Python FFMPEG support is enabled[0m
[2024-06-03 23:04] [34mWAS Node Suite [93mWarning: [0m`ffmpeg_bin_path` is not set in `/home/cash/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.[0m
[2024-06-03 23:04] [34mWAS Node Suite: [0mFinished.[0m [32mLoaded[0m [0m212[0m [32mnodes successfully.[0m
[2024-06-03 23:04] 
	[3m[93m"The future depends on what you do today."[0m[3m - Mahatma Gandhi[0m
[2024-06-03 23:04] 
[2024-06-03 23:04] ### Loading: ComfyUI-Impact-Pack (V5.8.1)
[2024-06-03 23:04] ### Loading: ComfyUI-Impact-Pack (Subpack: V0.5)
[2024-06-03 23:04] [Impact Pack] Wildcards loading done.
[2024-06-03 23:04] /home/cash/ComfyUI
[2024-06-03 23:04] ############################################
[2024-06-03 23:04] /home/cash/ComfyUI/custom_nodes/ComfyUI-NAI-styler/CSV
[2024-06-03 23:04] ############################################
[2024-06-03 23:04] []
[2024-06-03 23:04] ############################################
[2024-06-03 23:04] [Crystools [0;32mINFO[0m] Crystools version: 1.12.0
[2024-06-03 23:04] [Crystools [0;32mINFO[0m] CPU: 13th Gen Intel(R) Core(TM) i5-13500 - Arch: x86_64 - OS: Linux 5.15.0-107-generic
[2024-06-03 23:04] [Crystools [0;32mINFO[0m] GPU/s:
[2024-06-03 23:04] [Crystools [0;32mINFO[0m] 0) NVIDIA RTX 4000 SFF Ada Generation
[2024-06-03 23:04] [Crystools [0;32mINFO[0m] NVIDIA Driver: 535.161.08
[2024-06-03 23:04] ------------------------------------------
[2024-06-03 23:04] [34mComfyroll Studio v1.76 : [92m 175 Nodes Loaded[0m
[2024-06-03 23:04] ------------------------------------------
[2024-06-03 23:04] ** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md
[2024-06-03 23:04] ** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki
[2024-06-03 23:04] ------------------------------------------
[2024-06-03 23:04] OpenAI API key loaded
[2024-06-03 23:04] No module 'xformers'. Proceeding without it.
[2024-06-03 23:04] ### Loading: ComfyUI-Manager (V2.35.1)
[2024-06-03 23:04] ### ComfyUI Revision: 2218 [bf3e334d] | Released on '2024-05-30'
[2024-06-03 23:04] 
[2024-06-03 23:04] [92m[rgthree] Loaded 39 epic nodes.[0m
[2024-06-03 23:04] [92m[rgthree] Will use rgthree's optimized recursive execution.[0m
[2024-06-03 23:04] 
[2024-06-03 23:04] Total VRAM 20154 MB, total RAM 64103 MB
[2024-06-03 23:04] pytorch version: 2.3.0+cu121
[2024-06-03 23:04] Set vram state to: HIGH_VRAM
[2024-06-03 23:04] Device: cuda:0 NVIDIA RTX 4000 SFF Ada Generation : cudaMallocAsync
[2024-06-03 23:04] VAE dtype: torch.bfloat16
[2024-06-03 23:04] 
Import times for custom nodes:
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/websocket_image_save.py
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-Logic
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/comfyui-portrait-master
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-HyperSDXL1StepUnetScheduler
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-Universal-Styler
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI_essentials
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-Custom-Scripts
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI_UltimateSDUpscale
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-Advanced-ControlNet
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-KJNodes
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI_Comfyroll_CustomNodes
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/rgthree-comfy
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-TiledDiffusion
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-Manager
[2024-06-03 23:04]    0.0 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-Impact-Pack
[2024-06-03 23:04]    0.1 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-moondream
[2024-06-03 23:04]    0.2 seconds: /home/cash/ComfyUI/custom_nodes/comfyui_controlnet_aux
[2024-06-03 23:04]    0.4 seconds: /home/cash/ComfyUI/custom_nodes/eden_comfy_pipelines
[2024-06-03 23:04]    0.5 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-CCSR
[2024-06-03 23:04]    0.6 seconds: /home/cash/ComfyUI/custom_nodes/was-node-suite-comfyui
[2024-06-03 23:04]    2.2 seconds: /home/cash/ComfyUI/custom_nodes/ComfyUI-Crystools
[2024-06-03 23:04] 
[2024-06-03 23:04] Starting server

[2024-06-03 23:04] To see the GUI go to: http://0.0.0.0:8188
[2024-06-03 23:04] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json
[2024-06-03 23:04] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json
[2024-06-03 23:04] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[2024-06-03 23:04] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-06-03 23:04] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-06-03 23:04] FETCH DATA from: /home/cash/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]
[2024-06-03 23:04] Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press "Refresh".
                  Your current root directory is: /home/cash/ComfyUI
            
[2024-06-03 23:04] Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press "Refresh".
                  Your current root directory is: /home/cash/ComfyUI
            
[2024-06-03 23:04] Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press "Refresh".
                  Your current root directory is: /home/cash/ComfyUI
            
[2024-06-03 23:04] FETCH DATA from: /home/cash/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]
[2024-06-03 23:04] Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press "Refresh".
                  Your current root directory is: /home/cash/ComfyUI
            
[2024-06-03 23:04] Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press "Refresh".
                  Your current root directory is: /home/cash/ComfyUI
            
[2024-06-03 23:04] Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press "Refresh".
                  Your current root directory is: /home/cash/ComfyUI
            
[2024-06-03 23:06] got prompt
[2024-06-03 23:06] {'4': {'inputs': {'ckpt_name': 'redolives_v30.safetensors'}, 'class_type': 'CheckpointLoaderSimple', '_meta': {'title': 'Load Checkpoint'}}, '5': {'inputs': {'width': 512, 'height': 512, 'batch_size': 1}, 'class_type': 'EmptyLatentImage', '_meta': {'title': 'Empty Latent Image'}}, '6': {'inputs': {'text': 'An elderly women looking happy. sitting behind desk. facing camera', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '7': {'inputs': {'text': 'text, watermark, too many fingers, ugly, deformed, wrong number of fingers', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '8': {'inputs': {'samples': ['14', 0], 'vae': ['4', 2]}, 'class_type': 'VAEDecode', '_meta': {'title': 'VAE Decode'}}, '10': {'inputs': {'images': ['8', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '11': {'inputs': {'lora_name': 'LCM_LoRA_Weights_SDXL.safetensors', 'strength_model': 1, 'strength_clip': 1, 'model': ['4', 0], 'clip': ['4', 1]}, 'class_type': 'LoraLoader', '_meta': {'title': 'Load LoRA'}}, '12': {'inputs': {'sampling': 'lcm', 'zsnr': False, 'model': ['11', 0]}, 'class_type': 'ModelSamplingDiscrete', '_meta': {'title': 'ModelSamplingDiscrete'}}, '14': {'inputs': {'seed': 14279515014485, 'steps': 5, 'cfg': 1.8, 'sampler_name': 'lcm', 'scheduler': 'sgm_uniform', 'denoise': 1, 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'latent_image': ['5', 0]}, 'class_type': 'KSampler', '_meta': {'title': 'KSampler'}}, '18': {'inputs': {'model_name': 'bbox/face_yolov8m.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '19': {'inputs': {'guide_size': 256, 'guide_size_for': True, 'max_size': 1024, 'seed': 852968010114901, 'steps': 10, 'cfg': 8, 'sampler_name': 'dpmpp_2m', 'scheduler': 'karras', 'denoise': 0.5, 'feather': 5, 'noise_mask': True, 'force_inpaint': True, 'bbox_threshold': 0.5, 'bbox_dilation': 10, 'bbox_crop_factor': 3, 'sam_detection_hint': 'center-1', 'sam_dilation': 0, 'sam_threshold': 0.93, 'sam_bbox_expansion': 0, 'sam_mask_hint_threshold': 0.7, 'sam_mask_hint_use_negative': 'False', 'drop_size': 10, 'wildcard': '', 'cycle': 1, 'inpaint_model': False, 'noise_mask_feather': 20, 'image': ['8', 0], 'model': ['4', 0], 'clip': ['11', 1], 'vae': ['4', 2], 'positive': ['6', 0], 'negative': ['7', 0], 'bbox_detector': ['18', 0], 'sam_model_opt': ['25', 0], 'segm_detector_opt': ['20', 1]}, 'class_type': 'FaceDetailer', '_meta': {'title': 'FaceDetailer'}}, '20': {'inputs': {'model_name': 'segm/person_yolov8m-seg.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '25': {'inputs': {'model_name': 'sam_vit_b_01ec64.pth', 'device_mode': 'AUTO'}, 'class_type': 'SAMLoader', '_meta': {'title': 'SAMLoader (Impact)'}}, '26': {'inputs': {'images': ['19', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '33': {'inputs': {'upscale_by': 1.5, 'seed': 416380007678161, 'steps': 15, 'cfg': 7, 'sampler_name': 'dpmpp_sde', 'scheduler': 'karras', 'denoise': 0.1, 'mode_type': 'Linear', 'tile_width': 512, 'tile_height': 512, 'mask_blur': 8, 'tile_padding': 32, 'seam_fix_mode': 'None', 'seam_fix_denoise': 1, 'seam_fix_width': 64, 'seam_fix_mask_blur': 8, 'seam_fix_padding': 16, 'force_uniform_tiles': True, 'tiled_decode': False, 'image': ['19', 0], 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'vae': ['4', 2], 'upscale_model': ['35', 0]}, 'class_type': 'UltimateSDUpscale', '_meta': {'title': 'Ultimate SD Upscale'}}, '35': {'inputs': {'model_name': '4x_NMKD-Siax_200k.pth'}, 'class_type': 'UpscaleModelLoader', '_meta': {'title': 'Load Upscale Model'}}}
[2024-06-03 23:06] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-03 23:06] [32m[rgthree][0m First run patching recursive_output_delete_if_changed and recursive_will_execute.[0m
[2024-06-03 23:06] [33m[rgthree] Note: [0mIf execution seems broken due to forward ComfyUI changes, you can disable the optimization from rgthree settings in ComfyUI.[0m
[2024-06-03 23:06] model_type EPS
[2024-06-03 23:06] loaded straight to GPU
[2024-06-03 23:06] Requested to load SDXL
[2024-06-03 23:06] Loading 1 new model
[2024-06-03 23:06] Requested to load SDXLClipModel
[2024-06-03 23:06] Loading 1 new model
[2024-06-03 23:06] Requested to load SDXL
[2024-06-03 23:06] Loading 1 new model
[2024-06-03 23:06] 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  8.42it/s]100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  7.57it/s]
[2024-06-03 23:06] Requested to load TAESD
[2024-06-03 23:06] Loading 1 new model
[2024-06-03 23:06] Loads SAM model: /home/cash/ComfyUI/models/sams/sam_vit_b_01ec64.pth (device:AUTO)
[2024-06-03 23:06] 
[2024-06-03 23:06] 0: 640x640 1 face, 5.8ms
[2024-06-03 23:06] Speed: 1.6ms preprocess, 5.8ms inference, 10.3ms postprocess per image at shape (1, 3, 640, 640)
[2024-06-03 23:06] Detailer: segment upscale for ((125.83272, 171.82587)) | crop region (377, 512) x 2.001223597728695 -> (754, 1024)
[2024-06-03 23:06] Requested to load SDXL
[2024-06-03 23:06] Loading 1 new model
[2024-06-03 23:06] 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.54it/s]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.56it/s]
[2024-06-03 23:06] Prompt executed in 7.06 seconds
[2024-06-03 23:07] got prompt
[2024-06-03 23:07] {'4': {'inputs': {'ckpt_name': 'redolives_v30.safetensors'}, 'class_type': 'CheckpointLoaderSimple', '_meta': {'title': 'Load Checkpoint'}}, '5': {'inputs': {'width': 512, 'height': 512, 'batch_size': 1}, 'class_type': 'EmptyLatentImage', '_meta': {'title': 'Empty Latent Image'}}, '6': {'inputs': {'text': 'An elderly women looking happy. sitting behind desk. facing camera', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '7': {'inputs': {'text': 'text, watermark, too many fingers, ugly, deformed, wrong number of fingers', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '8': {'inputs': {'samples': ['14', 0], 'vae': ['4', 2]}, 'class_type': 'VAEDecode', '_meta': {'title': 'VAE Decode'}}, '10': {'inputs': {'images': ['8', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '11': {'inputs': {'lora_name': 'LCM_LoRA_Weights_SDXL.safetensors', 'strength_model': 1, 'strength_clip': 1, 'model': ['4', 0], 'clip': ['4', 1]}, 'class_type': 'LoraLoader', '_meta': {'title': 'Load LoRA'}}, '12': {'inputs': {'sampling': 'lcm', 'zsnr': False, 'model': ['11', 0]}, 'class_type': 'ModelSamplingDiscrete', '_meta': {'title': 'ModelSamplingDiscrete'}}, '14': {'inputs': {'seed': 174664429631364, 'steps': 5, 'cfg': 1.8, 'sampler_name': 'lcm', 'scheduler': 'sgm_uniform', 'denoise': 1, 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'latent_image': ['5', 0]}, 'class_type': 'KSampler', '_meta': {'title': 'KSampler'}}, '18': {'inputs': {'model_name': 'bbox/face_yolov8m.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '19': {'inputs': {'guide_size': 256, 'guide_size_for': True, 'max_size': 1024, 'seed': 331049004457825, 'steps': 10, 'cfg': 8, 'sampler_name': 'dpmpp_2m', 'scheduler': 'karras', 'denoise': 0.5, 'feather': 5, 'noise_mask': True, 'force_inpaint': True, 'bbox_threshold': 0.5, 'bbox_dilation': 10, 'bbox_crop_factor': 3, 'sam_detection_hint': 'center-1', 'sam_dilation': 0, 'sam_threshold': 0.93, 'sam_bbox_expansion': 0, 'sam_mask_hint_threshold': 0.7, 'sam_mask_hint_use_negative': 'False', 'drop_size': 10, 'wildcard': '', 'cycle': 1, 'inpaint_model': False, 'noise_mask_feather': 20, 'image': ['8', 0], 'model': ['4', 0], 'clip': ['11', 1], 'vae': ['4', 2], 'positive': ['6', 0], 'negative': ['7', 0], 'bbox_detector': ['18', 0], 'sam_model_opt': ['25', 0], 'segm_detector_opt': ['20', 1]}, 'class_type': 'FaceDetailer', '_meta': {'title': 'FaceDetailer'}}, '20': {'inputs': {'model_name': 'segm/person_yolov8m-seg.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '25': {'inputs': {'model_name': 'sam_vit_b_01ec64.pth', 'device_mode': 'AUTO'}, 'class_type': 'SAMLoader', '_meta': {'title': 'SAMLoader (Impact)'}}, '26': {'inputs': {'images': ['19', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '33': {'inputs': {'upscale_by': 1.5, 'seed': 416380007678161, 'steps': 15, 'cfg': 7, 'sampler_name': 'dpmpp_sde', 'scheduler': 'karras', 'denoise': 0.1, 'mode_type': 'Linear', 'tile_width': 512, 'tile_height': 512, 'mask_blur': 8, 'tile_padding': 32, 'seam_fix_mode': 'None', 'seam_fix_denoise': 1, 'seam_fix_width': 64, 'seam_fix_mask_blur': 8, 'seam_fix_padding': 16, 'force_uniform_tiles': True, 'tiled_decode': False, 'image': ['19', 0], 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'vae': ['4', 2], 'upscale_model': ['35', 0]}, 'class_type': 'UltimateSDUpscale', '_meta': {'title': 'Ultimate SD Upscale'}}, '35': {'inputs': {'model_name': '4x_NMKD-Siax_200k.pth'}, 'class_type': 'UpscaleModelLoader', '_meta': {'title': 'Load Upscale Model'}}}
[2024-06-03 23:07] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-03 23:07] Requested to load SDXL
[2024-06-03 23:07] Loading 1 new model
[2024-06-03 23:07] 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.43it/s]
[2024-06-03 23:07] 
[2024-06-03 23:07] 0: 640x640 1 face, 7.3ms
[2024-06-03 23:07] Speed: 1.0ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)
[2024-06-03 23:07] Detailer: segment upscale for ((137.90802, 171.68306)) | crop region (413, 512) x 1.8563097342978598 -> (766, 950)
[2024-06-03 23:07] Requested to load SDXL
[2024-06-03 23:07] Loading 1 new model
[2024-06-03 23:08] 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.67it/s]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.69it/s]
[2024-06-03 23:08] Prompt executed in 4.13 seconds
[2024-06-03 23:08] got prompt
[2024-06-03 23:08] {'4': {'inputs': {'ckpt_name': 'redolives_v30.safetensors'}, 'class_type': 'CheckpointLoaderSimple', '_meta': {'title': 'Load Checkpoint'}}, '5': {'inputs': {'width': 512, 'height': 512, 'batch_size': 1}, 'class_type': 'EmptyLatentImage', '_meta': {'title': 'Empty Latent Image'}}, '6': {'inputs': {'text': 'An elderly women looking disappointed. sitting behind desk. facing camera', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '7': {'inputs': {'text': 'text, watermark, too many fingers, ugly, deformed, wrong number of fingers', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '8': {'inputs': {'samples': ['14', 0], 'vae': ['4', 2]}, 'class_type': 'VAEDecode', '_meta': {'title': 'VAE Decode'}}, '10': {'inputs': {'images': ['8', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '11': {'inputs': {'lora_name': 'LCM_LoRA_Weights_SDXL.safetensors', 'strength_model': 1, 'strength_clip': 1, 'model': ['4', 0], 'clip': ['4', 1]}, 'class_type': 'LoraLoader', '_meta': {'title': 'Load LoRA'}}, '12': {'inputs': {'sampling': 'lcm', 'zsnr': False, 'model': ['11', 0]}, 'class_type': 'ModelSamplingDiscrete', '_meta': {'title': 'ModelSamplingDiscrete'}}, '14': {'inputs': {'seed': 37649343483664, 'steps': 5, 'cfg': 1.8, 'sampler_name': 'lcm', 'scheduler': 'sgm_uniform', 'denoise': 1, 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'latent_image': ['5', 0]}, 'class_type': 'KSampler', '_meta': {'title': 'KSampler'}}, '18': {'inputs': {'model_name': 'bbox/face_yolov8m.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '19': {'inputs': {'guide_size': 256, 'guide_size_for': True, 'max_size': 1024, 'seed': 814700421918909, 'steps': 10, 'cfg': 8, 'sampler_name': 'dpmpp_2m', 'scheduler': 'karras', 'denoise': 0.5, 'feather': 5, 'noise_mask': True, 'force_inpaint': True, 'bbox_threshold': 0.5, 'bbox_dilation': 10, 'bbox_crop_factor': 3, 'sam_detection_hint': 'center-1', 'sam_dilation': 0, 'sam_threshold': 0.93, 'sam_bbox_expansion': 0, 'sam_mask_hint_threshold': 0.7, 'sam_mask_hint_use_negative': 'False', 'drop_size': 10, 'wildcard': '', 'cycle': 1, 'inpaint_model': False, 'noise_mask_feather': 20, 'image': ['8', 0], 'model': ['4', 0], 'clip': ['11', 1], 'vae': ['4', 2], 'positive': ['6', 0], 'negative': ['7', 0], 'bbox_detector': ['18', 0], 'sam_model_opt': ['25', 0], 'segm_detector_opt': ['20', 1]}, 'class_type': 'FaceDetailer', '_meta': {'title': 'FaceDetailer'}}, '20': {'inputs': {'model_name': 'segm/person_yolov8m-seg.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '25': {'inputs': {'model_name': 'sam_vit_b_01ec64.pth', 'device_mode': 'AUTO'}, 'class_type': 'SAMLoader', '_meta': {'title': 'SAMLoader (Impact)'}}, '26': {'inputs': {'images': ['19', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '33': {'inputs': {'upscale_by': 1.5, 'seed': 416380007678161, 'steps': 15, 'cfg': 7, 'sampler_name': 'dpmpp_sde', 'scheduler': 'karras', 'denoise': 0.1, 'mode_type': 'Linear', 'tile_width': 512, 'tile_height': 512, 'mask_blur': 8, 'tile_padding': 32, 'seam_fix_mode': 'None', 'seam_fix_denoise': 1, 'seam_fix_width': 64, 'seam_fix_mask_blur': 8, 'seam_fix_padding': 16, 'force_uniform_tiles': True, 'tiled_decode': False, 'image': ['19', 0], 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'vae': ['4', 2], 'upscale_model': ['35', 0]}, 'class_type': 'UltimateSDUpscale', '_meta': {'title': 'Ultimate SD Upscale'}}, '35': {'inputs': {'model_name': '4x_NMKD-Siax_200k.pth'}, 'class_type': 'UpscaleModelLoader', '_meta': {'title': 'Load Upscale Model'}}}
[2024-06-03 23:08] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-03 23:08] Requested to load SDXL
[2024-06-03 23:08] Loading 1 new model
[2024-06-03 23:08] 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.38it/s]
[2024-06-03 23:08] 
[2024-06-03 23:08] 0: 640x640 1 face, 6.6ms
[2024-06-03 23:08] Speed: 1.0ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)
[2024-06-03 23:08] Detailer: segment upscale for ((148.53165, 188.52713)) | crop region (445, 512) x 1.7235384218685312 -> (766, 882)
[2024-06-03 23:08] Requested to load SDXL
[2024-06-03 23:08] Loading 1 new model
[2024-06-03 23:08] 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.90it/s]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.92it/s]
[2024-06-03 23:08] Prompt executed in 4.02 seconds
[2024-06-03 23:09] got prompt
[2024-06-03 23:09] {'4': {'inputs': {'ckpt_name': 'redolives_v30.safetensors'}, 'class_type': 'CheckpointLoaderSimple', '_meta': {'title': 'Load Checkpoint'}}, '5': {'inputs': {'width': 256, 'height': 256, 'batch_size': 1}, 'class_type': 'EmptyLatentImage', '_meta': {'title': 'Empty Latent Image'}}, '6': {'inputs': {'text': 'An elderly women looking disappointed. sitting behind desk. facing camera', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '7': {'inputs': {'text': 'text, watermark, too many fingers, ugly, deformed, wrong number of fingers', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '8': {'inputs': {'samples': ['14', 0], 'vae': ['4', 2]}, 'class_type': 'VAEDecode', '_meta': {'title': 'VAE Decode'}}, '10': {'inputs': {'images': ['8', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '11': {'inputs': {'lora_name': 'LCM_LoRA_Weights_SDXL.safetensors', 'strength_model': 1, 'strength_clip': 1, 'model': ['4', 0], 'clip': ['4', 1]}, 'class_type': 'LoraLoader', '_meta': {'title': 'Load LoRA'}}, '12': {'inputs': {'sampling': 'lcm', 'zsnr': False, 'model': ['11', 0]}, 'class_type': 'ModelSamplingDiscrete', '_meta': {'title': 'ModelSamplingDiscrete'}}, '14': {'inputs': {'seed': 890921531545606, 'steps': 5, 'cfg': 1.8, 'sampler_name': 'lcm', 'scheduler': 'sgm_uniform', 'denoise': 1, 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'latent_image': ['5', 0]}, 'class_type': 'KSampler', '_meta': {'title': 'KSampler'}}, '18': {'inputs': {'model_name': 'bbox/face_yolov8m.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '19': {'inputs': {'guide_size': 256, 'guide_size_for': True, 'max_size': 1024, 'seed': 295791131765226, 'steps': 10, 'cfg': 8, 'sampler_name': 'dpmpp_2m', 'scheduler': 'karras', 'denoise': 0.5, 'feather': 5, 'noise_mask': True, 'force_inpaint': True, 'bbox_threshold': 0.5, 'bbox_dilation': 10, 'bbox_crop_factor': 3, 'sam_detection_hint': 'center-1', 'sam_dilation': 0, 'sam_threshold': 0.93, 'sam_bbox_expansion': 0, 'sam_mask_hint_threshold': 0.7, 'sam_mask_hint_use_negative': 'False', 'drop_size': 10, 'wildcard': '', 'cycle': 1, 'inpaint_model': False, 'noise_mask_feather': 20, 'image': ['8', 0], 'model': ['4', 0], 'clip': ['11', 1], 'vae': ['4', 2], 'positive': ['6', 0], 'negative': ['7', 0], 'bbox_detector': ['18', 0], 'sam_model_opt': ['25', 0], 'segm_detector_opt': ['20', 1]}, 'class_type': 'FaceDetailer', '_meta': {'title': 'FaceDetailer'}}, '20': {'inputs': {'model_name': 'segm/person_yolov8m-seg.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '25': {'inputs': {'model_name': 'sam_vit_b_01ec64.pth', 'device_mode': 'AUTO'}, 'class_type': 'SAMLoader', '_meta': {'title': 'SAMLoader (Impact)'}}, '26': {'inputs': {'images': ['19', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '33': {'inputs': {'upscale_by': 1.5, 'seed': 416380007678161, 'steps': 15, 'cfg': 7, 'sampler_name': 'dpmpp_sde', 'scheduler': 'karras', 'denoise': 0.1, 'mode_type': 'Linear', 'tile_width': 512, 'tile_height': 512, 'mask_blur': 8, 'tile_padding': 32, 'seam_fix_mode': 'None', 'seam_fix_denoise': 1, 'seam_fix_width': 64, 'seam_fix_mask_blur': 8, 'seam_fix_padding': 16, 'force_uniform_tiles': True, 'tiled_decode': False, 'image': ['19', 0], 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'vae': ['4', 2], 'upscale_model': ['35', 0]}, 'class_type': 'UltimateSDUpscale', '_meta': {'title': 'Ultimate SD Upscale'}}, '35': {'inputs': {'model_name': '4x_NMKD-Siax_200k.pth'}, 'class_type': 'UpscaleModelLoader', '_meta': {'title': 'Load Upscale Model'}}}
[2024-06-03 23:09] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-03 23:09] Requested to load SDXL
[2024-06-03 23:09] Loading 1 new model
[2024-06-03 23:09] 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 15.52it/s]100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 14.74it/s]
[2024-06-03 23:09] 
[2024-06-03 23:09] 0: 640x640 1 face, 6.0ms
[2024-06-03 23:09] Speed: 1.1ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)
[2024-06-03 23:09] Detailer: segment upscale for ((79.35374, 106.53648)) | crop region (238, 256) x 3.2260610536260126 -> (767, 825)
[2024-06-03 23:09] Requested to load SDXL
[2024-06-03 23:09] Loading 1 new model
[2024-06-03 23:09] 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.17it/s]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.19it/s]
[2024-06-03 23:09] Prompt executed in 3.60 seconds
[2024-06-03 23:09] got prompt
[2024-06-03 23:09] {'4': {'inputs': {'ckpt_name': 'redolives_v30.safetensors'}, 'class_type': 'CheckpointLoaderSimple', '_meta': {'title': 'Load Checkpoint'}}, '5': {'inputs': {'width': 512, 'height': 512, 'batch_size': 1}, 'class_type': 'EmptyLatentImage', '_meta': {'title': 'Empty Latent Image'}}, '6': {'inputs': {'text': 'An elderly women looking disappointed. sitting behind desk. facing camera', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '7': {'inputs': {'text': 'text, watermark, too many fingers, ugly, deformed, wrong number of fingers', 'clip': ['11', 1]}, 'class_type': 'CLIPTextEncode', '_meta': {'title': 'CLIP Text Encode (Prompt)'}}, '8': {'inputs': {'samples': ['14', 0], 'vae': ['4', 2]}, 'class_type': 'VAEDecode', '_meta': {'title': 'VAE Decode'}}, '10': {'inputs': {'images': ['8', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '11': {'inputs': {'lora_name': 'LCM_LoRA_Weights_SDXL.safetensors', 'strength_model': 1, 'strength_clip': 1, 'model': ['4', 0], 'clip': ['4', 1]}, 'class_type': 'LoraLoader', '_meta': {'title': 'Load LoRA'}}, '12': {'inputs': {'sampling': 'lcm', 'zsnr': False, 'model': ['11', 0]}, 'class_type': 'ModelSamplingDiscrete', '_meta': {'title': 'ModelSamplingDiscrete'}}, '14': {'inputs': {'seed': 905853358582179, 'steps': 5, 'cfg': 1.8, 'sampler_name': 'lcm', 'scheduler': 'sgm_uniform', 'denoise': 1, 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'latent_image': ['5', 0]}, 'class_type': 'KSampler', '_meta': {'title': 'KSampler'}}, '18': {'inputs': {'model_name': 'bbox/face_yolov8m.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '19': {'inputs': {'guide_size': 256, 'guide_size_for': True, 'max_size': 1024, 'seed': 824255202978272, 'steps': 10, 'cfg': 8, 'sampler_name': 'dpmpp_2m', 'scheduler': 'karras', 'denoise': 0.5, 'feather': 5, 'noise_mask': True, 'force_inpaint': True, 'bbox_threshold': 0.5, 'bbox_dilation': 10, 'bbox_crop_factor': 3, 'sam_detection_hint': 'center-1', 'sam_dilation': 0, 'sam_threshold': 0.93, 'sam_bbox_expansion': 0, 'sam_mask_hint_threshold': 0.7, 'sam_mask_hint_use_negative': 'False', 'drop_size': 10, 'wildcard': '', 'cycle': 1, 'inpaint_model': False, 'noise_mask_feather': 20, 'image': ['8', 0], 'model': ['4', 0], 'clip': ['11', 1], 'vae': ['4', 2], 'positive': ['6', 0], 'negative': ['7', 0], 'bbox_detector': ['18', 0], 'sam_model_opt': ['25', 0], 'segm_detector_opt': ['20', 1]}, 'class_type': 'FaceDetailer', '_meta': {'title': 'FaceDetailer'}}, '20': {'inputs': {'model_name': 'segm/person_yolov8m-seg.pt'}, 'class_type': 'UltralyticsDetectorProvider', '_meta': {'title': 'UltralyticsDetectorProvider'}}, '25': {'inputs': {'model_name': 'sam_vit_b_01ec64.pth', 'device_mode': 'AUTO'}, 'class_type': 'SAMLoader', '_meta': {'title': 'SAMLoader (Impact)'}}, '26': {'inputs': {'images': ['19', 0]}, 'class_type': 'PreviewImage', '_meta': {'title': 'Preview Image'}}, '33': {'inputs': {'upscale_by': 1.5, 'seed': 416380007678161, 'steps': 15, 'cfg': 7, 'sampler_name': 'dpmpp_sde', 'scheduler': 'karras', 'denoise': 0.1, 'mode_type': 'Linear', 'tile_width': 512, 'tile_height': 512, 'mask_blur': 8, 'tile_padding': 32, 'seam_fix_mode': 'None', 'seam_fix_denoise': 1, 'seam_fix_width': 64, 'seam_fix_mask_blur': 8, 'seam_fix_padding': 16, 'force_uniform_tiles': True, 'tiled_decode': False, 'image': ['19', 0], 'model': ['12', 0], 'positive': ['6', 0], 'negative': ['7', 0], 'vae': ['4', 2], 'upscale_model': ['35', 0]}, 'class_type': 'UltimateSDUpscale', '_meta': {'title': 'Ultimate SD Upscale'}}, '35': {'inputs': {'model_name': '4x_NMKD-Siax_200k.pth'}, 'class_type': 'UpscaleModelLoader', '_meta': {'title': 'Load Upscale Model'}}}
[2024-06-03 23:09] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-03 23:09] Requested to load SDXL
[2024-06-03 23:09] Loading 1 new model
[2024-06-03 23:09] 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.52it/s]
[2024-06-03 23:09] 
[2024-06-03 23:09] 0: 640x640 1 face, 7.3ms
[2024-06-03 23:09] Speed: 1.0ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)
[2024-06-03 23:09] Detailer: segment upscale for ((175.94025, 236.54318)) | crop region (512, 512) x 1.4550394521621937 -> (744, 744)
[2024-06-03 23:09] Requested to load SDXL
[2024-06-03 23:09] Loading 1 new model
[2024-06-03 23:10] 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.87it/s]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.89it/s]
[2024-06-03 23:10] Prompt executed in 3.46 seconds
[2024-06-03 23:24] 
Stopped server
